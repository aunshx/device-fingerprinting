{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import joblib\n",
    "import json\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the JSON data\n",
    "with open('../data/extracted_and_reformatted_data.json', 'r') as file:\n",
    "    json_data = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entryId</th>\n",
       "      <th>browserData</th>\n",
       "      <th>operationDetails</th>\n",
       "      <th>operationOutput</th>\n",
       "      <th>components</th>\n",
       "      <th>platform</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2501</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_inverse_saw_tooth', '...</td>\n",
       "      <td>[62.0, 23.0, 121.0, 36.0, 20.0, 4975.0, 77.0, ...</td>\n",
       "      <td>{'fonts': {'value': ['Arabic Typesetting', 'Ba...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>744.6000</td>\n",
       "      <td>1783.131650</td>\n",
       "      <td>0.000</td>\n",
       "      <td>9303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31066</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[6.714999675750732, 19.454999826848507, 17.815...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 102}, 'dom...</td>\n",
       "      <td>macOS</td>\n",
       "      <td>16.9993</td>\n",
       "      <td>17.302972</td>\n",
       "      <td>3.610</td>\n",
       "      <td>73.980000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>32059</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[38.16500003449619, 11.799999978393316, 37.215...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 46}, 'domB...</td>\n",
       "      <td>macOS</td>\n",
       "      <td>63.0564</td>\n",
       "      <td>36.484954</td>\n",
       "      <td>5.990</td>\n",
       "      <td>194.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>26061</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[134.0100000379607, 321.53999991714954, 753.10...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 2343}, 'do...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>894.4812</td>\n",
       "      <td>516.625525</td>\n",
       "      <td>97.235</td>\n",
       "      <td>2533.650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>52602</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[31.884999945759773, 1512.275000102818, 2693.9...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 2415}, 'do...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>1345.6076</td>\n",
       "      <td>2604.141791</td>\n",
       "      <td>0.000</td>\n",
       "      <td>12178.610000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54022</th>\n",
       "      <td>23278</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[14.710000017657876, 88.61500001512468, 29.815...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 196}, 'dom...</td>\n",
       "      <td>macOS</td>\n",
       "      <td>229.7320</td>\n",
       "      <td>230.288465</td>\n",
       "      <td>6.165</td>\n",
       "      <td>1123.255000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54023</th>\n",
       "      <td>29869</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[16.580000519752502, 8.229999803006649, 279.88...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 2569}, 'do...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>159.9590</td>\n",
       "      <td>124.756627</td>\n",
       "      <td>8.230</td>\n",
       "      <td>501.809999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54024</th>\n",
       "      <td>43047</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[1280.7550001889467, 1033.9449997991323, 632.3...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 2273}, 'do...</td>\n",
       "      <td>Windows</td>\n",
       "      <td>1271.2530</td>\n",
       "      <td>1595.840569</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5705.545000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54026</th>\n",
       "      <td>15611</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[32.44499955326319, 26.405000127851963, 49.999...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 66}, 'domB...</td>\n",
       "      <td>macOS</td>\n",
       "      <td>34.4791</td>\n",
       "      <td>36.735076</td>\n",
       "      <td>4.100</td>\n",
       "      <td>222.475000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54027</th>\n",
       "      <td>15597</td>\n",
       "      <td>Host: frieza.herokuapp.com\\nConnection: close\\...</td>\n",
       "      <td>{'executableName': 'exec_step', 'executableDur...</td>\n",
       "      <td>[7.389999998849817, 510.6999999989057, 530.780...</td>\n",
       "      <td>{'fonts': {'value': [], 'duration': 496}, 'dom...</td>\n",
       "      <td>macOS</td>\n",
       "      <td>392.5029</td>\n",
       "      <td>334.780721</td>\n",
       "      <td>6.380</td>\n",
       "      <td>1635.810000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37813 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       entryId                                        browserData   \n",
       "1         2501  Host: frieza.herokuapp.com\\nConnection: close\\...  \\\n",
       "3        31066  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "6        32059  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "7        26061  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "8        52602  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "...        ...                                                ...   \n",
       "54022    23278  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "54023    29869  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "54024    43047  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "54026    15611  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "54027    15597  Host: frieza.herokuapp.com\\nConnection: close\\...   \n",
       "\n",
       "                                        operationDetails   \n",
       "1      {'executableName': 'exec_inverse_saw_tooth', '...  \\\n",
       "3      {'executableName': 'exec_step', 'executableDur...   \n",
       "6      {'executableName': 'exec_step', 'executableDur...   \n",
       "7      {'executableName': 'exec_step', 'executableDur...   \n",
       "8      {'executableName': 'exec_step', 'executableDur...   \n",
       "...                                                  ...   \n",
       "54022  {'executableName': 'exec_step', 'executableDur...   \n",
       "54023  {'executableName': 'exec_step', 'executableDur...   \n",
       "54024  {'executableName': 'exec_step', 'executableDur...   \n",
       "54026  {'executableName': 'exec_step', 'executableDur...   \n",
       "54027  {'executableName': 'exec_step', 'executableDur...   \n",
       "\n",
       "                                         operationOutput   \n",
       "1      [62.0, 23.0, 121.0, 36.0, 20.0, 4975.0, 77.0, ...  \\\n",
       "3      [6.714999675750732, 19.454999826848507, 17.815...   \n",
       "6      [38.16500003449619, 11.799999978393316, 37.215...   \n",
       "7      [134.0100000379607, 321.53999991714954, 753.10...   \n",
       "8      [31.884999945759773, 1512.275000102818, 2693.9...   \n",
       "...                                                  ...   \n",
       "54022  [14.710000017657876, 88.61500001512468, 29.815...   \n",
       "54023  [16.580000519752502, 8.229999803006649, 279.88...   \n",
       "54024  [1280.7550001889467, 1033.9449997991323, 632.3...   \n",
       "54026  [32.44499955326319, 26.405000127851963, 49.999...   \n",
       "54027  [7.389999998849817, 510.6999999989057, 530.780...   \n",
       "\n",
       "                                              components platform       mean   \n",
       "1      {'fonts': {'value': ['Arabic Typesetting', 'Ba...  Windows   744.6000  \\\n",
       "3      {'fonts': {'value': [], 'duration': 102}, 'dom...    macOS    16.9993   \n",
       "6      {'fonts': {'value': [], 'duration': 46}, 'domB...    macOS    63.0564   \n",
       "7      {'fonts': {'value': [], 'duration': 2343}, 'do...  Windows   894.4812   \n",
       "8      {'fonts': {'value': [], 'duration': 2415}, 'do...  Windows  1345.6076   \n",
       "...                                                  ...      ...        ...   \n",
       "54022  {'fonts': {'value': [], 'duration': 196}, 'dom...    macOS   229.7320   \n",
       "54023  {'fonts': {'value': [], 'duration': 2569}, 'do...  Windows   159.9590   \n",
       "54024  {'fonts': {'value': [], 'duration': 2273}, 'do...  Windows  1271.2530   \n",
       "54026  {'fonts': {'value': [], 'duration': 66}, 'domB...    macOS    34.4791   \n",
       "54027  {'fonts': {'value': [], 'duration': 496}, 'dom...    macOS   392.5029   \n",
       "\n",
       "               std     min           max  \n",
       "1      1783.131650   0.000   9303.000000  \n",
       "3        17.302972   3.610     73.980000  \n",
       "6        36.484954   5.990    194.470000  \n",
       "7       516.625525  97.235   2533.650000  \n",
       "8      2604.141791   0.000  12178.610000  \n",
       "...            ...     ...           ...  \n",
       "54022   230.288465   6.165   1123.255000  \n",
       "54023   124.756627   8.230    501.809999  \n",
       "54024  1595.840569   0.000   5705.545000  \n",
       "54026    36.735076   4.100    222.475000  \n",
       "54027   334.780721   6.380   1635.810000  \n",
       "\n",
       "[37813 rows x 10 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Preprocess the data\n",
    "''' \n",
    "\n",
    "# Convert the JSON data to a DataFrame\n",
    "df = pd.DataFrame(json_data)\n",
    "\n",
    "fixed_length = 50\n",
    "\n",
    "def convert_and_pad_or_truncate(arr, length):\n",
    "    arr = np.fromstring(arr.strip('[]'), sep=',').tolist()\n",
    "    if len(arr) > length:\n",
    "        return arr[:length]\n",
    "    elif len(arr) < length:\n",
    "        return np.pad(arr, (0, length - len(arr)), 'constant')\n",
    "    return arr\n",
    "\n",
    "# Apply padding/truncation to each operationOutput\n",
    "df['operationOutput'] = df['operationOutput'].apply(lambda x: convert_and_pad_or_truncate(x, fixed_length))\n",
    "\n",
    "# Determine the plaform of the data\n",
    "def determine_platform(platform):\n",
    "    if 'Linux' in platform:\n",
    "        return 'Linux'\n",
    "    elif 'Win' in platform:\n",
    "        return 'Windows'\n",
    "    elif 'iPad' in platform or 'iPhone' in platform:\n",
    "        # return 'iOS'\n",
    "        return 'macOS'\n",
    "    elif 'Mac' in platform:\n",
    "        return 'macOS'\n",
    "    else:\n",
    "        return 'Other'\n",
    "\n",
    "# Get the platform from component\n",
    "df['platform'] = df['components'].apply(lambda x: determine_platform(x['platform']['value']))\n",
    "\n",
    "# Remove all linux data\n",
    "df = df[df['platform'] != 'Linux']\n",
    "\n",
    "# Compute summary statistics for each operationOutput\n",
    "df['mean'] = df['operationOutput'].apply(np.mean)\n",
    "df['std'] = df['operationOutput'].apply(np.std)\n",
    "df['min'] = df['operationOutput'].apply(np.min)\n",
    "df['max'] = df['operationOutput'].apply(np.max)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min Samples: 16818\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Get number of classes and balance the data\n",
    "'''\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = df['platform'].nunique()\n",
    "\n",
    "# find min number of samples in the classes\n",
    "min_samples = df['platform'].value_counts().min()\n",
    "print(\"Min Samples:\",min_samples)\n",
    "# Balance the data\n",
    "df = df.groupby('platform').apply(lambda x: x.sample(n=min_samples)).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Feature Engineering\n",
    "'''\n",
    "\n",
    "X = np.vstack(df['operationOutput'].values)\n",
    "X = np.hstack([X, df[['mean', 'std', 'min', 'max']].values])\n",
    "y = df['platform']\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Windows' 'macOS']\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Encode labels\n",
    "'''\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "print(f\"Classes: {label_encoder.classes_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Split the data\n",
    "'''\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\doodl\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Build Model\n",
    "'''\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(512, activation='relu', input_shape=(X_train.shape[1],), kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(256, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu', kernel_regularizer=l2(0.01)),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "    Dense(len(label_encoder.classes_), activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and learning rate reduction\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "673/673 - 8s - 11ms/step - accuracy: 0.4990 - loss: 4.2678 - val_accuracy: 0.5098 - val_loss: 1.7454 - learning_rate: 0.0010\n",
      "Epoch 2/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4987 - loss: 1.1052 - val_accuracy: 0.5046 - val_loss: 0.7995 - learning_rate: 0.0010\n",
      "Epoch 3/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4968 - loss: 0.7471 - val_accuracy: 0.5015 - val_loss: 0.7237 - learning_rate: 0.0010\n",
      "Epoch 4/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5026 - loss: 0.7244 - val_accuracy: 0.5030 - val_loss: 0.7483 - learning_rate: 0.0010\n",
      "Epoch 5/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5087 - loss: 0.7220 - val_accuracy: 0.5091 - val_loss: 0.7217 - learning_rate: 0.0010\n",
      "Epoch 6/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4989 - loss: 0.7285 - val_accuracy: 0.4861 - val_loss: 0.7363 - learning_rate: 0.0010\n",
      "Epoch 7/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5033 - loss: 0.7301 - val_accuracy: 0.4905 - val_loss: 0.7250 - learning_rate: 0.0010\n",
      "Epoch 8/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5031 - loss: 0.7319 - val_accuracy: 0.5160 - val_loss: 0.7357 - learning_rate: 0.0010\n",
      "Epoch 9/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4993 - loss: 0.7270 - val_accuracy: 0.5046 - val_loss: 0.7355 - learning_rate: 0.0010\n",
      "Epoch 10/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4951 - loss: 0.7266 - val_accuracy: 0.4928 - val_loss: 0.7193 - learning_rate: 0.0010\n",
      "Epoch 11/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5029 - loss: 0.7303 - val_accuracy: 0.4935 - val_loss: 0.7468 - learning_rate: 0.0010\n",
      "Epoch 12/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5030 - loss: 0.7288 - val_accuracy: 0.5061 - val_loss: 0.7260 - learning_rate: 0.0010\n",
      "Epoch 13/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5018 - loss: 0.7220 - val_accuracy: 0.5123 - val_loss: 0.7166 - learning_rate: 0.0010\n",
      "Epoch 14/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4998 - loss: 0.7186 - val_accuracy: 0.5020 - val_loss: 0.7071 - learning_rate: 0.0010\n",
      "Epoch 15/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4986 - loss: 0.7137 - val_accuracy: 0.4937 - val_loss: 0.7108 - learning_rate: 0.0010\n",
      "Epoch 16/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5000 - loss: 0.7088 - val_accuracy: 0.4920 - val_loss: 0.7216 - learning_rate: 0.0010\n",
      "Epoch 17/100\n",
      "673/673 - 6s - 8ms/step - accuracy: 0.4998 - loss: 0.7061 - val_accuracy: 0.5043 - val_loss: 0.7060 - learning_rate: 0.0010\n",
      "Epoch 18/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5007 - loss: 0.7057 - val_accuracy: 0.5007 - val_loss: 0.7142 - learning_rate: 0.0010\n",
      "Epoch 19/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5026 - loss: 0.7065 - val_accuracy: 0.4890 - val_loss: 0.7016 - learning_rate: 0.0010\n",
      "Epoch 20/100\n",
      "673/673 - 4s - 5ms/step - accuracy: 0.4926 - loss: 0.7012 - val_accuracy: 0.4849 - val_loss: 0.7003 - learning_rate: 0.0010\n",
      "Epoch 21/100\n",
      "673/673 - 4s - 5ms/step - accuracy: 0.4991 - loss: 0.6993 - val_accuracy: 0.4946 - val_loss: 0.6988 - learning_rate: 0.0010\n",
      "Epoch 22/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4953 - loss: 0.6985 - val_accuracy: 0.5061 - val_loss: 0.6976 - learning_rate: 0.0010\n",
      "Epoch 23/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4986 - loss: 0.6982 - val_accuracy: 0.4883 - val_loss: 0.6940 - learning_rate: 0.0010\n",
      "Epoch 24/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5000 - loss: 0.6975 - val_accuracy: 0.4872 - val_loss: 0.6983 - learning_rate: 0.0010\n",
      "Epoch 25/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4959 - loss: 0.6967 - val_accuracy: 0.5117 - val_loss: 0.6954 - learning_rate: 0.0010\n",
      "Epoch 26/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4939 - loss: 0.6950 - val_accuracy: 0.4889 - val_loss: 0.6948 - learning_rate: 0.0010\n",
      "Epoch 27/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5008 - loss: 0.6965 - val_accuracy: 0.4935 - val_loss: 0.6964 - learning_rate: 0.0010\n",
      "Epoch 28/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4946 - loss: 0.6956 - val_accuracy: 0.5024 - val_loss: 0.6947 - learning_rate: 0.0010\n",
      "Epoch 29/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5028 - loss: 0.6954 - val_accuracy: 0.4955 - val_loss: 0.6988 - learning_rate: 0.0010\n",
      "Epoch 30/100\n",
      "673/673 - 4s - 5ms/step - accuracy: 0.5014 - loss: 0.6968 - val_accuracy: 0.5117 - val_loss: 0.6939 - learning_rate: 0.0010\n",
      "Epoch 31/100\n",
      "673/673 - 5s - 8ms/step - accuracy: 0.4978 - loss: 0.6942 - val_accuracy: 0.4957 - val_loss: 0.6937 - learning_rate: 0.0010\n",
      "Epoch 32/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4907 - loss: 0.6947 - val_accuracy: 0.5117 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 33/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5029 - loss: 0.6944 - val_accuracy: 0.4883 - val_loss: 0.6945 - learning_rate: 0.0010\n",
      "Epoch 34/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4959 - loss: 0.6936 - val_accuracy: 0.4883 - val_loss: 0.6935 - learning_rate: 0.0010\n",
      "Epoch 35/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5030 - loss: 0.6932 - val_accuracy: 0.4883 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 36/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4955 - loss: 0.6933 - val_accuracy: 0.4883 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 37/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4913 - loss: 0.6933 - val_accuracy: 0.4883 - val_loss: 0.6937 - learning_rate: 0.0010\n",
      "Epoch 38/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5033 - loss: 0.6932 - val_accuracy: 0.4883 - val_loss: 0.6935 - learning_rate: 0.0010\n",
      "Epoch 39/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5007 - loss: 0.6932 - val_accuracy: 0.5117 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 40/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4909 - loss: 0.6954 - val_accuracy: 0.5080 - val_loss: 0.6934 - learning_rate: 0.0010\n",
      "Epoch 41/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5070 - loss: 0.6948 - val_accuracy: 0.5117 - val_loss: 0.6954 - learning_rate: 0.0010\n",
      "Epoch 42/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4948 - loss: 0.6936 - val_accuracy: 0.4954 - val_loss: 0.6938 - learning_rate: 0.0010\n",
      "Epoch 43/100\n",
      "673/673 - 5s - 8ms/step - accuracy: 0.5041 - loss: 0.6934 - val_accuracy: 0.4883 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 44/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5007 - loss: 0.6932 - val_accuracy: 0.5117 - val_loss: 0.6930 - learning_rate: 0.0010\n",
      "Epoch 45/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4929 - loss: 0.6933 - val_accuracy: 0.5117 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 46/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4958 - loss: 0.6933 - val_accuracy: 0.4883 - val_loss: 0.6935 - learning_rate: 0.0010\n",
      "Epoch 47/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4968 - loss: 0.6948 - val_accuracy: 0.4883 - val_loss: 0.7070 - learning_rate: 0.0010\n",
      "Epoch 48/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5010 - loss: 0.6954 - val_accuracy: 0.5019 - val_loss: 0.6950 - learning_rate: 0.0010\n",
      "Epoch 49/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5048 - loss: 0.6951 - val_accuracy: 0.5117 - val_loss: 0.6936 - learning_rate: 0.0010\n",
      "Epoch 50/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4969 - loss: 0.6948 - val_accuracy: 0.4981 - val_loss: 0.6937 - learning_rate: 0.0010\n",
      "Epoch 51/100\n",
      "673/673 - 4s - 5ms/step - accuracy: 0.4935 - loss: 0.6934 - val_accuracy: 0.5117 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 52/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.5061 - loss: 0.6943 - val_accuracy: 0.5117 - val_loss: 0.6955 - learning_rate: 0.0010\n",
      "Epoch 53/100\n",
      "673/673 - 3s - 5ms/step - accuracy: 0.4988 - loss: 0.6939 - val_accuracy: 0.5117 - val_loss: 0.6931 - learning_rate: 0.0010\n",
      "Epoch 54/100\n",
      "673/673 - 3s - 4ms/step - accuracy: 0.4987 - loss: 0.6933 - val_accuracy: 0.4883 - val_loss: 0.6932 - learning_rate: 0.0010\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Train the model\n",
    "'''\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping, reduce_lr], verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m211/211\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy: 49.46%\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Test accuracy\n",
    "'''\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "accuracy = accuracy_score(y_test, y_pred_classes)\n",
    "print(f\"Accuracy: {accuracy * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
